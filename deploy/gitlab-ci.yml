stages:
  - setup
  - compilers
  - externals
  - applications
  - checks

default:
  tags: [bb5_map]  # Will use a special deployment user with write permissions to `bsd`
  timeout: 3 day   # Building takes a while

# This is a blatant copy of the documentation deployment setup from `nse/ci`
# FIXME purge this once the move to GitLab is complete
.spack_setup_gerrit_ssh:
  - SSH_CONFIG=$HOME/.ssh/config
  - if [[ -f $SSH_CONFIG ]]; then echo "SSH config file $SSH_CONFIG already exists, exiting"; exit 1; fi
  - if [[ -z $BBPCIHPCDEPLOY_GERRIT_PRIVATE_KEY ]]; then echo 'Please set the $BBPCIHPCDEPLOY_GERRIT_PRIVATE_KEY variable'; exit 1; fi
  - |
    mkdir -p $(dirname $SSH_CONFIG) && cat > $SSH_CONFIG <<EOF
    User $(whoami)
    IdentityFile ${BBPCIHPCDEPLOY_GERRIT_PRIVATE_KEY}
    StrictHostKeyChecking no
    IdentitiesOnly yes
    EOF
  - chmod 600 $SSH_CONFIG $BBPCIHPCDEPLOY_GERRIT_PRIVATE_KEY

.spack_basic_job:
  variables:
    # Max out duration to install stuff
    bb5_duration: "24:00:00"
    # We will do this ourselves, will be on GPFS
    GIT_STRATEGY: none
  before_script:
    # Tell Git how to re-write BBP GitLab URLs to use a token instead of SSH
    - export XDG_CONFIG_HOME=${PWD}/local_config
    - mkdir -p "${XDG_CONFIG_HOME}/git"
    - echo -e "[url \"https://gitlab-ci-token:${CI_JOB_TOKEN}@bbpgitlab.epfl.ch/\"]\n  insteadOf = git@bbpgitlab.epfl.ch:" > "${XDG_CONFIG_HOME}/git/config"
    - cat "${XDG_CONFIG_HOME}/git/config"

# This prepares the environment for the rest of the pipeline.  Could have
# been a simple function in a CI environment with a proper DSL ¯\_(ツ)_/¯
#
# Needed as jobs can't inherit from this *and* augment the rules
setup_environment:
  stage: .pre
  extends: .spack_basic_job
  variables:
    # bb5_build_dir: pipeline
    # We will do this ourselves, will be on GPFS
    GIT_STRATEGY: none
    # All the variables below should be added to `deployment.env` to build
    # the basis for further stages without relying to much on the
    # `variables` key of GitLab
    #
    # Needed for Intel compilers, which may re-use some libraries from a
    # GCC
    BASE_GCC_VERSION: "9.3.0"
    DEPLOYMENT_BRANCH: "transition-g2g"
    # Proprietary sources
    DEPLOYMENT_DATA: "/gpfs/bbp.cscs.ch/ssd/apps/hpc/download"
    # This date should increment for new deployments — about once a year
    DEPLOYMENT_DATE: "2021-09"
    # All directories below should change for pull requests (replacing the
    # date)
    DEPLOYMENT_ROOT: "/gpfs/bbp.cscs.ch/ssd/apps/bsd/$DEPLOYMENT_DATE"
    DEPLOYMENT_UPSTREAM: "/gpfs/bbp.cscs.ch/ssd/apps/bsd/$DEPLOYMENT_DATE"
    DEPLOYMENT_PROPRIETARY_MIRROR: "/gpfs/bbp.cscs.ch/ssd/apps/bsd/$DEPLOYMENT_DATE/mirror/proprietary"
  rules:
    - if: '$CI_COMMIT_REF_NAME == "transition-g2g"'  # $CI_DEFAULT_BRANCH
      when: always
    - if: '$CI_EXTERNAL_PULL_REQUEST_IID'
      variables:
        DEPLOYMENT_BRANCH: "$CI_EXTERNAL_PULL_REQUEST_SOURCE_BRANCH_NAME"
        DEPLOYMENT_ROOT: "/gpfs/bbp.cscs.ch/ssd/apps/bsd/pulls/$CI_EXTERNAL_PULL_REQUEST_IID"
        DEPLOYMENT_PROPRIETARY_MIRROR: "/gpfs/bbp.cscs.ch/ssd/apps/bsd/pulls/$CI_EXTERNAL_PULL_REQUEST_IID/mirror/proprietary"
      when: always
    - when: never
  script:
    # The `rules` keyword seems to not inherit variables specified via a
    # dotenv ⇒ do things manually once more
    - echo "BASE_GCC_VERSION=$BASE_GCC_VERSION" > deployment.env
    - echo "DEPLOYMENT_BRANCH=$DEPLOYMENT_BRANCH" >> deployment.env
    - echo "DEPLOYMENT_DATA=$DEPLOYMENT_DATA" >> deployment.env
    - echo "DEPLOYMENT_DATE=$DEPLOYMENT_DATE" >> deployment.env
    - echo "DEPLOYMENT_ROOT=$DEPLOYMENT_ROOT" >> deployment.env
    - echo "DEPLOYMENT_UPSTREAM=$DEPLOYMENT_UPSTREAM" >> deployment.env
    - echo "DEPLOYMENT_PROPRIETARY_MIRROR=$DEPLOYMENT_PROPRIETARY_MIRROR" >> deployment.env
    # DEBUG
    - rm -rf /gpfs/bbp.cscs.ch/ssd/apps/bsd/2021-09/stage_externals/install_-
  artifacts:
    when: always
    paths: [deployment.env]
    reports:
      dotenv: deployment.env

setup_spack:
  extends: .spack_basic_job
  needs: [setup_environment]
  stage: setup
  script:
    - pwd
    - set -x
    - echo "Cloning/updating spack repository"
    - |
      if [[ -d "$DEPLOYMENT_ROOT/spack" ]]; then
          cd "$DEPLOYMENT_ROOT/spack"
          git fetch origin "$DEPLOYMENT_BRANCH"
          git reset --hard "$CI_COMMIT_SHORT_SHA"
          git status
      else
          git clone --branch "$DEPLOYMENT_BRANCH" --single-branch https://github.com/BlueBrain/spack.git "$DEPLOYMENT_ROOT/spack"
          cd "$DEPLOYMENT_ROOT/spack"
      fi
      git describe
      git log --oneline -n5
    - echo "Cloning/updating license repository"
    - |
      export LICENSE_ROOT="$DEPLOYMENT_ROOT/spack/etc/spack/licenses"
      if [[ -d "$LICENSE_ROOT" ]]; then
          cd "$LICENSE_ROOT"
          git fetch
          git reset --hard FETCH_HEAD
          git status
      else
      git clone --single-branch git@bbpgitlab.epfl.ch:hpc/spack-licenses.git "$LICENSE_ROOT"
          cd "$LICENSE_ROOT"
      fi
      git log --oneline -n5
    # Global values that are even appropriate for end-users
    - cp "${DEPLOYMENT_ROOT}/spack/deploy/configs/"*.yaml "${DEPLOYMENT_ROOT}/spack/etc/spack"
  # Just loop this stuff through…
  artifacts:
    when: always
    paths: [deployment.env]
    reports:
      dotenv: deployment.env

# This is the basic setup for one of our deployment stages. Things to
# consider:
# * The GitLab CI stage will set the installation directory for all
#   software
# * The GitLab CI job name will set the environment to use. Meaning that
#   `deploy/environments/${CI_JOB_NAME}.yaml` has to exist and be a valid
#   Spack environment
# * Subsequent deployment stages have to depend on each other to pass
#   exported entities like compilers and external packages through
.spack_stage:
  extends: .spack_basic_job
  needs: [setup_spack]
  before_script:
    - !reference [.spack_setup_gerrit_ssh]
    - !reference [.spack_basic_job, before_script]
    # Supplementary scripts
    - export PATH="${DEPLOYMENT_ROOT}/spack/deploy/bin:${PATH}"
    # Clean test stacks and miscellaneous files from previous stages
    - rm -rf stack-*xml missing.txt specs.txt
    # These variables will interfere with building software
    - unset $(set +x; env | awk -F= '/^(PMI|SLURM)_/ {print $1}' | xargs)
    # Create a local Spack configuration directory if not present from
    # artifacts of previous jobs, link it into $HOME for Spack to pick up
    - if [[ ! -d spack_config ]]; then
    -     mkdir spack_config
    - fi
    - ln -sf "${PWD}/spack_config" "${HOME}/.spack"
    # Configure installation directories et al based on the job's stage:
    # this keeps environment files simpler
    - |
      DEPLOYMENT_SUFFIX=""
      if [[ "$CI_JOB_STAGE" != "$CI_JOB_NAME" ]]; then
          DEPLOYMENT_SUFFIX="_$CI_JOB_NAME"
      fi
      cat <<EOF > "spack_config/config.yaml"
      config:
        install_tree:
          root: $DEPLOYMENT_ROOT/stage_${CI_JOB_STAGE}
          projections:
            all: install_\${COMPILERNAME}-\${COMPILERVER}/\${PACKAGE}-\${VERSION}-\${HASH:6}
        module_roots:
          tcl: $DEPLOYMENT_ROOT/stage_${CI_JOB_STAGE}/modules_tcl$DEPLOYMENT_SUFFIX
      EOF
    # Hook up software from other stages if needed (also for PRs)
    - configure-upstreams > "spack_config/upstreams.yaml"
    # Sourcing should happen after upstreams to add upstream modules to the path
    - source "$DEPLOYMENT_ROOT/spack/share/spack/setup-env.sh"
    # Verify the above
    - spack config blame config
    - spack config blame upstreams
    - echo "$MODULEPATH"|sed 's/:/\n/g'
    # Set up a mirror for proprietary software for the external stage; only
    # populate it once per pipeline, all other stages will receive the same
    # configuration
    - if [[ "${CI_JOB_STAGE}" == "compilers" ]]; then
    -     spack mirror add --scope=user my_proprietary_mirror "file://${DEPLOYMENT_PROPRIETARY_MIRROR}"
    -     mkdir -p "${DEPLOYMENT_PROPRIETARY_MIRROR}"
    -     rsync -av "${DEPLOYMENT_DATA}/" "${DEPLOYMENT_PROPRIETARY_MIRROR}"
    - elif [[ "${CI_JOB_STAGE}" == "applications" ]]; then
    -     module use "$DEPLOYMENT_ROOT/stage_compilers/modules_tcl"
    -     module use "$DEPLOYMENT_ROOT/stage_externals/modules_tcl"
    - fi
  script:
    # Remove any old Spack environment and recreate it, using the version
    # controlled template
    - export DEPLOY_ENV="${CI_JOB_STAGE}${DEPLOYMENT_SUFFIX}-$(date +%Y-%m)"
    - echo "Processing environment ${DEPLOY_ENV}"
    - if [[ -n "$(spack env list|grep "${DEPLOY_ENV}")" ]]; then
    -     spack env remove -y "${DEPLOY_ENV}"
    - fi
    - spack env create "${DEPLOY_ENV}" "${SPACK_ROOT}/deploy/environments/${CI_JOB_STAGE}${DEPLOYMENT_SUFFIX}.yaml"
    - spack env activate "${DEPLOY_ENV}"
    # Concretize and pre-fetch, afterwards build the environment
    - spack concretize -f
    - installed-hashes -m|tee missing.txt
    - if [[ -n "$(<missing.txt)" ]]; then
    -     spack -d fetch -m
    -     srun -N1 -n4 -c12 -t24:0:0 -Aproj9998 -Ccpu -pprod -J"spack!" slurmspack
    - fi
    # We always want to regenerate the modules and compiler configurations,
    # as they may change independenty of package dependencies and shas
    - installed-hashes|tee specs.txt
    - shas="$(cut -d" " -f1 specs.txt)"
    - spack module tcl refresh -y --delete-tree --upstream-modules ${shas}
    - if [[ "${CI_JOB_STAGE}" == "compilers" ]]; then
    # This will be needed by future compiler finds: extract the one base
    # gcc used in the compiler stage.
    -     export BASE_GCC_HASH="/$(spack find --format '{hash:7}' gcc@$BASE_GCC_VERSION)"
    -     echo "BASE_GCC_HASH=$BASE_GCC_HASH" >> deployment.env
    # Make compilers here available to following stages
    -     configure-compilers < specs.txt
    - elif [[ "${CI_JOB_STAGE}" == "externals" ]]; then
    # Make compilers here available to following stages
    -     configure-compilers < specs.txt
    # Make all explicitly installed software available to following stages
    # without considering the full dependency DAG
    -     spack export --scope=user --module tcl --explicit --exclude 'allinea|neuron|hdf5|intel-parallel-studio|pgi|nvhpc' ${shas} > "spack_config/packages.yaml"
    - fi
  artifacts:
    when: always
    paths:
      - deployment.env
      - missing.txt
      - specs.txt
      - spack_config/*.yaml
      - stack-*.xml
    reports:
      junit: stack-*.xml
      dotenv: deployment.env

compilers:
  extends: .spack_stage
  stage: compilers

externals:
  extends: .spack_stage
  needs: [compilers]
  stage: externals

libraries:
  extends: .spack_stage
  needs: [externals]
  stage: applications
